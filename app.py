# app.py - ì™„ì „ ìˆ˜ì • ë²„ì „
import streamlit as st
import boto3
from datetime import datetime
import time
import os

st.set_page_config(page_title="S3 Log Analyzer Setup", page_icon="ğŸ“Š")

class AthenaTableCreator:
    def __init__(self, region_name='us-east-1'):
        self.region = region_name
        self.s3_client = boto3.client('s3', region_name=region_name)
        self.athena_client = boto3.client('athena', region_name=region_name)
        self.glue_client = boto3.client('glue', region_name=region_name)
        
    def list_s3_buckets(self):
        """S3 ë²„í‚· ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.s3_client.list_buckets()
            return [bucket['Name'] for bucket in response['Buckets']]
        except Exception as e:
            st.error(f"Error listing buckets: {str(e)}")
            return []
    
    def list_s3_folders(self, bucket_name, prefix=''):
        """S3 ë²„í‚· ë‚´ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            paginator = self.s3_client.get_paginator('list_objects_v2')
            folders = set()
            
            for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix, Delimiter='/'):
                if 'CommonPrefixes' in page:
                    for prefix_info in page['CommonPrefixes']:
                        folders.add(prefix_info['Prefix'])
            
            return sorted(list(folders))
        except Exception as e:
            st.error(f"Error listing folders: {str(e)}")
            return []
    
    def verify_log_files(self, bucket_name, prefix=''):
        """ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸"""
        try:
            response = self.s3_client.list_objects_v2(
                Bucket=bucket_name,
                Prefix=prefix,
                MaxKeys=5
            )
            
            if 'Contents' in response:
                files = [obj['Key'] for obj in response['Contents']]
                return True, files
            else:
                return False, []
        except Exception as e:
            return False, [str(e)]
    
    def create_database(self, database_name, s3_output_location):
        """Athena ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
        query = f"CREATE DATABASE IF NOT EXISTS {database_name}"
        
        response = self.athena_client.start_query_execution(
            QueryString=query,
            ResultConfiguration={'OutputLocation': s3_output_location}
        )
        
        return response['QueryExecutionId']
    
    def create_s3_access_log_table(self, database_name, table_name, s3_location, s3_output_location):
        """S3 Access Log í…Œì´ë¸” ìë™ ìƒì„± - ì˜¬ë°”ë¥¸ RegEx íŒ¨í„´"""
        
        # ì˜¬ë°”ë¥¸ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        create_table_query = f"""
        CREATE EXTERNAL TABLE IF NOT EXISTS `{database_name}.{table_name}`(
          `bucketowner` STRING, 
          `bucket_name` STRING, 
          `requestdatetime` STRING, 
          `remoteip` STRING, 
          `requester` STRING, 
          `requestid` STRING, 
          `operation` STRING, 
          `key` STRING, 
          `request_uri` STRING, 
          `httpstatus` STRING, 
          `errorcode` STRING, 
          `bytessent` BIGINT, 
          `objectsize` BIGINT, 
          `totaltime` STRING, 
          `turnaroundtime` STRING, 
          `referrer` STRING, 
          `useragent` STRING, 
          `versionid` STRING, 
          `hostid` STRING, 
          `sigv` STRING, 
          `ciphersuite` STRING, 
          `authtype` STRING, 
          `endpoint` STRING, 
          `tlsversion` STRING,
          `accesspointarn` STRING,
          `aclrequired` STRING)
        ROW FORMAT SERDE 
          'org.apache.hadoop.hive.serde2.RegexSerDe' 
        WITH SERDEPROPERTIES ( 
          'input.regex'='([^ ]*) ([^ ]*) \\\\[(.*?)\\\\] ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) (\"[^\"]*\"|-) (-|[0-9]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) (\"[^\"]*\"|-) ([^ ]*)(?: ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*))?.*$$') 
        STORED AS INPUTFORMAT 
          'org.apache.hadoop.mapred.TextInputFormat' 
        OUTPUTFORMAT 
          'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
        LOCATION
          '{s3_location}'
        """
        
        response = self.athena_client.start_query_execution(
            QueryString=create_table_query,
            QueryExecutionContext={'Database': database_name},
            ResultConfiguration={'OutputLocation': s3_output_location}
        )
        
        return response['QueryExecutionId']
    
    def test_table_query(self, database_name, table_name, s3_output_location):
        """í…Œì´ë¸” ë°ì´í„° í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬"""
        test_query = f"SELECT COUNT(*) as row_count FROM {database_name}.{table_name}"
        
        response = self.athena_client.start_query_execution(
            QueryString=test_query,
            QueryExecutionContext={'Database': database_name},
            ResultConfiguration={'OutputLocation': s3_output_location}
        )
        
        return response['QueryExecutionId']
    
    def get_query_result(self, query_execution_id):
        """ì¿¼ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.athena_client.get_query_results(
                QueryExecutionId=query_execution_id,
                MaxResults=1
            )
            
            if response['ResultSet']['Rows']:
                if len(response['ResultSet']['Rows']) > 1:
                    return response['ResultSet']['Rows'][1]['Data'][0].get('VarCharValue', '0')
            return '0'
        except:
            return 'Error'
    
    def wait_for_query(self, query_execution_id):
        """ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°"""
        max_attempts = 30
        for i in range(max_attempts):
            response = self.athena_client.get_query_execution(
                QueryExecutionId=query_execution_id
            )
            status = response['QueryExecution']['Status']['State']
            
            if status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:
                return status, response
            
            time.sleep(1)
        
        return 'TIMEOUT', response

# Streamlit UI
def main():
    st.title("ğŸš€ S3 Log Analyzer - Auto Setup")
    st.markdown("S3 Access Logë¥¼ ìœ„í•œ Athena í…Œì´ë¸”ì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤")
    
    # ì‚¬ìš©ì ì•ˆë‚´ ì •ë³´
    with st.expander("â„¹ï¸ How to get AWS Credentials", expanded=False):
        st.markdown("""
        ### AWS ìê²© ì¦ëª…ì„ ì–»ëŠ” ë°©ë²•:
        
        1. **AWS Console ë¡œê·¸ì¸** â†’ IAM ì„œë¹„ìŠ¤ë¡œ ì´ë™
        2. **Users** â†’ ë³¸ì¸ ì‚¬ìš©ì ì„ íƒ (ë˜ëŠ” ìƒˆ ì‚¬ìš©ì ìƒì„±)
        3. **Security credentials** íƒ­ â†’ **Create access key**
        4. **Use case**: Command Line Interface (CLI) ì„ íƒ
        5. **Access Key ID**ì™€ **Secret Access Key** ë³µì‚¬
        
        ### í•„ìš”í•œ ê¶Œí•œ:
        - `AmazonS3ReadOnlyAccess` (S3 ë²„í‚· ëª©ë¡ ì¡°íšŒìš©)
        - `AmazonAthenaFullAccess` (Athena í…Œì´ë¸” ìƒì„±ìš©)
        - `AWSGlueConsoleFullAccess` (Glue ì¹´íƒˆë¡œê·¸ ì ‘ê·¼ìš©)
        
        ### ë³´ì•ˆ ì£¼ì˜ì‚¬í•­:
        - ìê²© ì¦ëª…ì€ ì´ ì„¸ì…˜ì—ì„œë§Œ ì‚¬ìš©ë˜ë©° ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤
        - ì‚¬ìš© í›„ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìœ¼ë©´ ìë™ìœ¼ë¡œ ì‚­ì œë©ë‹ˆë‹¤
        - ê°€ëŠ¥í•˜ë©´ ì„ì‹œ ìê²© ì¦ëª…ì´ë‚˜ ì œí•œëœ ê¶Œí•œì„ ì‚¬ìš©í•˜ì„¸ìš”
        """)
    
    st.markdown("---")
    
    # Sidebar ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        # AWS ë¦¬ì „ ì„ íƒ
        regions = [
            'us-east-1', 'us-west-2', 'eu-west-1', 'eu-central-1',
            'ap-northeast-1', 'ap-northeast-2', 'ap-southeast-1', 'ap-southeast-2'
        ]
        
        default_region = os.environ.get('AWS_DEFAULT_REGION', 'us-east-1')
        
        selected_region = st.selectbox(
            "AWS Region",
            regions,
            index=regions.index(default_region) if default_region in regions else 0,
            help="Select the AWS region where your S3 buckets are located"
        )
        
        # Athena ê²°ê³¼ ì €ì¥ ìœ„ì¹˜
        athena_output = st.text_input(
            "Athena Output Location",
            value=f"s3://athena-results-{datetime.now().strftime('%Y%m%d')}/",
            help="Athena ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì €ì¥í•  S3 ìœ„ì¹˜"
        )
        
        # AWS ìê²© ì¦ëª… ì…ë ¥
        st.subheader("ğŸ” AWS Credentials")
        
        # ìê²© ì¦ëª… ì…ë ¥ ë°©ë²• ì„ íƒ
        auth_method = st.radio(
            "Authentication Method",
            ["Enter Credentials", "Use Environment/Secrets"],
            help="Choose how to provide AWS credentials"
        )
        
        aws_access_key = None
        aws_secret_key = None
        
        if auth_method == "Enter Credentials":
            st.info("ğŸ’¡ Your credentials are only used for this session and are not stored")
            aws_access_key = st.text_input(
                "AWS Access Key ID",
                type="password",
                help="Your AWS Access Key ID"
            )
            aws_secret_key = st.text_input(
                "AWS Secret Access Key", 
                type="password",
                help="Your AWS Secret Access Key"
            )
            
            if aws_access_key and aws_secret_key:
                st.success("âœ… Credentials entered")
            elif aws_access_key or aws_secret_key:
                st.warning("âš ï¸ Please enter both Access Key ID and Secret Access Key")
        
        else:  # Use Environment/Secrets
            # Streamlit Cloudì—ì„œ secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
            aws_access_key = st.secrets.get("AWS_ACCESS_KEY_ID", os.environ.get("AWS_ACCESS_KEY_ID"))
            aws_secret_key = st.secrets.get("AWS_SECRET_ACCESS_KEY", os.environ.get("AWS_SECRET_ACCESS_KEY"))
            
            if aws_access_key and aws_secret_key:
                st.success("âœ… Using configured credentials")
            else:
                st.error("âŒ No credentials found in environment or secrets")
                st.info("Configure AWS credentials in Streamlit secrets or environment variables")
        
        # ìê²© ì¦ëª… ê²€ì¦
        if aws_access_key and aws_secret_key:
            try:
                sts = boto3.client(
                    'sts', 
                    region_name=selected_region,
                    aws_access_key_id=aws_access_key,
                    aws_secret_access_key=aws_secret_key
                )
                identity = sts.get_caller_identity()
                st.success(f"âœ… Connected as: {identity['Arn'].split('/')[-1]}")
            except Exception as e:
                st.error(f"âŒ AWS credentials error: {str(e)}")
                st.info("Please check your credentials and try again")
                return
        else:
            st.error("âŒ Please provide AWS credentials to continue")
            return
    
    # AthenaTableCreator ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìê²© ì¦ëª…ì€ sidebarì—ì„œ ì´ë¯¸ ê²€ì¦ë¨)
    try:
        creator = AthenaTableCreator(region_name=selected_region)
        # AWS í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„± (ìê²© ì¦ëª… í¬í•¨)
        creator.s3_client = boto3.client(
            's3', 
            region_name=selected_region,
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key
        )
        creator.athena_client = boto3.client(
            'athena', 
            region_name=selected_region,
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key
        )
        creator.glue_client = boto3.client(
            'glue', 
            region_name=selected_region,
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key
        )
    except Exception as e:
        st.error(f"Failed to initialize AWS clients: {str(e)}")
        return
    
    # Main UI
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ S3 Log Location")
        
        # ë²„í‚· ì„ íƒ
        buckets = creator.list_s3_buckets()
        if not buckets:
            st.warning("No S3 buckets found in this region")
            return
            
        selected_bucket = st.selectbox("Select Log Bucket", buckets)
        
        # í´ë” ì„ íƒ (ì„ íƒì‚¬í•­)
        if selected_bucket:
            folders = creator.list_s3_folders(selected_bucket)
            if folders:
                selected_folder = st.selectbox("Select Folder (Optional)", [''] + folders)
            else:
                selected_folder = ''
                st.info("No folders found in bucket")
    
    with col2:
        st.subheader("ğŸ—„ï¸ Database Configuration")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ìë™ ìƒì„±
        safe_bucket_name = selected_bucket.replace('-', '_').replace('.', '_')
        default_db_name = f"s3_logs_{safe_bucket_name}"[:64]
        db_name = st.text_input("Database Name", value=default_db_name)
        
        # í…Œì´ë¸” ì´ë¦„ ìë™ ìƒì„±
        default_table_name = "access_logs"
        table_name = st.text_input("Table Name", value=default_table_name)
    
    # S3 ê²½ë¡œ ë¯¸ë¦¬ë³´ê¸°
    s3_location = f"s3://{selected_bucket}/"
    if selected_folder:
        s3_location = f"s3://{selected_bucket}/{selected_folder}"
        # í´ë” ì„ íƒ ì‹œ ëì˜ ìŠ¬ë˜ì‹œ ì œê±° (ì´ë¯¸ í´ë”ëª…ì— í¬í•¨ë¨)
        if s3_location.endswith('//'):
            s3_location = s3_location[:-1]
    
    st.info(f"ğŸ“ S3 Location: `{s3_location}`")
    st.info(f"ğŸŒ Region: `{selected_region}`")
    
    # ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if st.button("ğŸ” Verify Log Files"):
        prefix = selected_folder if selected_folder else ''
        exists, files = creator.verify_log_files(selected_bucket, prefix)
        
        if exists:
            st.success(f"âœ… Found {len(files)} log files")
            with st.expander("View sample files"):
                for file in files[:5]:
                    st.text(file)
        else:
            st.warning("âš ï¸ No log files found in this location")
            st.info("Make sure S3 Server Access Logging is enabled and logs have been generated")
    
    # ìƒì„± ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ¯ Create Database & Table", type="primary", use_container_width=True):
            with st.spinner("Creating resources..."):
                try:
                    # 1. ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
                    st.write("1ï¸âƒ£ Creating database...")
                    db_query_id = creator.create_database(db_name, athena_output)
                    status, _ = creator.wait_for_query(db_query_id)
                    
                    if status == 'SUCCEEDED':
                        st.success(f"âœ… Database '{db_name}' created!")
                    else:
                        st.error(f"Failed to create database: {status}")
                        return
                    
                    # 2. í…Œì´ë¸” ìƒì„±
                    st.write("2ï¸âƒ£ Creating table...")
                    table_query_id = creator.create_s3_access_log_table(
                        db_name, table_name, s3_location, athena_output
                    )
                    status, response = creator.wait_for_query(table_query_id)
                    
                    if status == 'SUCCEEDED':
                        st.success(f"âœ… Table '{db_name}.{table_name}' created!")
                        
                        # 3. ë°ì´í„° í™•ì¸
                        st.write("3ï¸âƒ£ Verifying data...")
                        test_query_id = creator.test_table_query(db_name, table_name, athena_output)
                        test_status, _ = creator.wait_for_query(test_query_id)
                        
                        if test_status == 'SUCCEEDED':
                            row_count = creator.get_query_result(test_query_id)
                            if row_count != '0' and row_count != 'Error':
                                st.success(f"âœ… Table contains {row_count} rows of data!")
                            else:
                                st.warning("âš ï¸ Table created but no data found")
                                st.info(f"""
                                Possible reasons:
                                1. Log files haven't been generated yet (wait 5-15 minutes)
                                2. Wrong S3 location selected (current: {s3_location})
                                3. Log format mismatch
                                
                                Try these queries in Athena console:
                                ```sql
                                -- Check table
                                SELECT * FROM {db_name}.{table_name} LIMIT 10;
                                
                                -- Show table location
                                SHOW CREATE TABLE {db_name}.{table_name};
                                ```
                                """)
                        
                        st.balloons()
                        
                        with st.expander("ğŸ“‹ Sample Queries"):
                            st.markdown(f"""
                            ```sql
                            -- Check if data exists
                            SELECT COUNT(*) FROM {db_name}.{table_name};
                            
                            -- View first 10 logs
                            SELECT * FROM {db_name}.{table_name} LIMIT 10;
                            
                            -- Count by HTTP status
                            SELECT httpstatus, COUNT(*) as count
                            FROM {db_name}.{table_name}
                            WHERE httpstatus IS NOT NULL
                            GROUP BY httpstatus
                            ORDER BY count DESC;
                            
                            -- Find 404 errors
                            SELECT requestdatetime, key, remoteip, httpstatus
                            FROM {db_name}.{table_name}
                            WHERE httpstatus = '404';
                            
                            -- Top requested files
                            SELECT key, COUNT(*) as requests
                            FROM {db_name}.{table_name}
                            WHERE key IS NOT NULL
                            GROUP BY key
                            ORDER BY requests DESC
                            LIMIT 20;
                            ```
                            """)
                    else:
                        st.error(f"Failed to create table: {status}")
                        if 'QueryExecution' in response and 'Status' in response['QueryExecution']:
                            if 'StateChangeReason' in response['QueryExecution']['Status']:
                                st.error(response['QueryExecution']['Status']['StateChangeReason'])
                
                except Exception as e:
                    st.error(f"Error: {str(e)}")
    
    # ë””ë²„ê¹… ì„¹ì…˜
    with st.expander("ğŸ”§ Troubleshooting & Manual DDL"):
        st.markdown("""
        ### If no data appears:
        
        1. **Verify log files exist** using the "Verify Log Files" button above
        2. **Check S3 path** - make sure it points to where log files are stored
        3. **Wait for logs** - S3 Access Logs can take 5-15 minutes to appear
        
        ### Manual DDL for Athena Console:
        Copy and paste this into Athena console, replacing the LOCATION:
        """)
        
        st.code(f"""
                CREATE EXTERNAL TABLE `s3_access_logs_db.mybucket_logs`(
                `bucketowner` STRING, 
                `bucket_name` STRING, 
                `requestdatetime` STRING, 
                `remoteip` STRING, 
                `requester` STRING, 
                `requestid` STRING, 
                `operation` STRING, 
                `key` STRING, 
                `request_uri` STRING, 
                `httpstatus` STRING, 
                `errorcode` STRING, 
                `bytessent` BIGINT, 
                `objectsize` BIGINT, 
                `totaltime` STRING, 
                `turnaroundtime` STRING, 
                `referrer` STRING, 
                `useragent` STRING, 
                `versionid` STRING, 
                `hostid` STRING, 
                `sigv` STRING, 
                `ciphersuite` STRING, 
                `authtype` STRING, 
                `endpoint` STRING, 
                `tlsversion` STRING,
                `accesspointarn` STRING,
                `aclrequired` STRING)
                ROW FORMAT SERDE 
                'org.apache.hadoop.hive.serde2.RegexSerDe' 
                WITH SERDEPROPERTIES ( 
                'input.regex'='([^ ]*) ([^ ]*) \\[(.*?)\\] ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) (\"[^\"]*\"|-) (-|[0-9]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) (\"[^\"]*\"|-) ([^ ]*)(?: ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*))?.*$') 
                STORED AS INPUTFORMAT 
                'org.apache.hadoop.mapred.TextInputFormat' 
                OUTPUTFORMAT 
                'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
                LOCATION '{s3_location}';
                """, language='sql'
                )

if __name__ == "__main__":
    main()
